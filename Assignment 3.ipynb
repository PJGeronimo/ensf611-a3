{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: Paolo Geronimo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b67a661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2af8bd32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "import yellowbrick.datasets\n",
    "X, y = yellowbrick.datasets.loaders.load_concrete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fdc93a78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>47.279761</td>\n",
       "      <td>73.447331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>29.577455</td>\n",
       "      <td>45.059351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>3.37944</td>\n",
       "      <td>22.783221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Training Accuracy Validation Accuracy\n",
       "DT         47.279761           73.447331\n",
       "RF         29.577455           45.059351\n",
       "GB           3.37944           22.783221"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "decision_tree = DecisionTreeRegressor(max_depth = 5, random_state = 0).fit(X_train, y_train)\n",
    "random_forest = RandomForestRegressor(max_depth = 5, random_state = 0).fit(X_train, y_train)\n",
    "gradient_boosting = GradientBoostingRegressor(max_depth = 5, random_state = 0).fit(X_train, y_train)\n",
    "\n",
    "models = [decision_tree, random_forest, gradient_boosting]\n",
    "results = pd.DataFrame(index = [\"DT\", \"RF\", \"GB\"], columns = [\"Training Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "for index in range(len(models)):\n",
    "    model = models[index]\n",
    "    scores = cross_validate(model, X_train, y_train, scoring = \"neg_mean_squared_error\", return_train_score = True)\n",
    "    results.iloc[index, 0] = scores['train_score'].mean() * -1\n",
    "    results.iloc[index, 1] = scores['test_score'].mean() * -1\n",
    "    \n",
    "results\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.834465</td>\n",
       "      <td>0.738697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.896557</td>\n",
       "      <td>0.840927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.988171</td>\n",
       "      <td>0.919471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Training Accuracy Validation Accuracy\n",
       "DT          0.834465            0.738697\n",
       "RF          0.896557            0.840927\n",
       "GB          0.988171            0.919471"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "for index in range(len(models)):\n",
    "    model = models[index]\n",
    "    scores = cross_validate(model, X_train, y_train, scoring = \"r2\", return_train_score = True)\n",
    "    results.iloc[index, 0] = scores['train_score'].mean()\n",
    "    results.iloc[index, 1] = scores['test_score'].mean()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "*ANSWER HERE*\n",
    "1. These results are generally a significant improvement compared to the linear models in the previous assignment. For example, the Training MSEs were ~111 and the Validation MSEs were ~95 for the linear models. Compared to the non-linear models which had MSEs between ~47 and ~3. Taking a look at the R2 scores, the linear models had R2 scores of ~0.6 for both the Training and Validation results. Here, the R2 scores are between ~0.73 and ~0.98.\n",
    "\n",
    "2. Out of all the models we have tested, the Gradient Boosting Model has the best performance. Looking at the MSEs, the Gradient Boosting Model's MSE is a fraction of the other two models, at ~3.4 for the Training set and ~22.8 for the Validation set. The model also definitively has the best R2 Scores, at ~0.99 for the Training and ~0.92 for the validation. Another thing that makes the Gradient Boosting model is its balance between bias and variance. Looking at the R2 Scores, the Random Forest has the smallest difference between the training and validation scores, making it the model with the highest bias. The Decision Tree has the greatest difference between the training and validation scores, making it the model with the highest variance.\n",
    "\n",
    "3. To increase the accuracy of tree based models, max_depth can be increased. Also, n_estimators can be increased for Random Forest and Gradient Boosing models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. My code is sourced from my previous assignment, where I gathered inspiration on how to implement the loop. I also took a look at Decision Trees Example from D2L on how to use the cross_validate() method. \n",
    "2. I completed the steps in chronological order. \n",
    "3. I did not use generative AI to complete this section, the examples found on D2L and scikit's website were enough material. \n",
    "4. My biggest challenge was understanding how to use and access the results from the cross_validate() method. Taking a look at scikit's documentation on the method (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html), I realized the method returns a dictionary of arrays. I realized I had to access the appropriate keys, find the mean of the values, and append it to the results DataFrames. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types in X:\n",
      "Alcohol                         float64\n",
      "Malicacid                       float64\n",
      "Ash                             float64\n",
      "Alcalinity_of_ash               float64\n",
      "Magnesium                         int64\n",
      "Total_phenols                   float64\n",
      "Flavanoids                      float64\n",
      "Nonflavanoid_phenols            float64\n",
      "Proanthocyanins                 float64\n",
      "Color_intensity                 float64\n",
      "Hue                             float64\n",
      "0D280_0D315_of_diluted_wines    float64\n",
      "Proline                           int64\n",
      "dtype: object\n",
      "Shape of X: (178, 13)\n",
      "\n",
      "Types in y:\n",
      "int64\n",
      "Shape of y: (178,)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "\n",
    "# import data, set column names\n",
    "column_names = [\"Class\", \"Alcohol\", \"Malicacid\", \"Ash\", \"Alcalinity_of_ash\", \"Magnesium\", \"Total_phenols\", \"Flavanoids\", \"Nonflavanoid_phenols\", \"Proanthocyanins\", \"Color_intensity\", \"Hue\", \"0D280_0D315_of_diluted_wines\", \"Proline\"]\n",
    "X = pd.read_csv(\"wine.data\", names = column_names)\n",
    "\n",
    "# splitting into feature matrix and target vector\n",
    "y = X[\"Class\"]\n",
    "X = X.drop(\"Class\", axis = 1)\n",
    "\n",
    "print(\"Types in X:\")\n",
    "print(X.dtypes)\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "\n",
    "print(\"\\nTypes in y:\")\n",
    "print(y.dtypes)\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "0    14.23       1.71  2.43               15.6        127           2.80   \n",
       "1    13.20       1.78  2.14               11.2        100           2.65   \n",
       "2    13.16       2.36  2.67               18.6        101           2.80   \n",
       "3    14.37       1.95  2.50               16.8        113           3.85   \n",
       "4    13.24       2.59  2.87               21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   0D280_0D315_of_diluted_wines  Proline  \n",
       "0                          3.92     1065  \n",
       "1                          3.40     1050  \n",
       "2                          3.17     1185  \n",
       "3                          3.45     1480  \n",
       "4                          2.93      735  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "X.iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol                         0\n",
      "Malicacid                       0\n",
      "Ash                             0\n",
      "Alcalinity_of_ash               0\n",
      "Magnesium                       0\n",
      "Total_phenols                   0\n",
      "Flavanoids                      0\n",
      "Nonflavanoid_phenols            0\n",
      "Proanthocyanins                 0\n",
      "Color_intensity                 0\n",
      "Hue                             0\n",
      "0D280_0D315_of_diluted_wines    0\n",
      "Proline                         0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(X.isnull().sum())\n",
    "print(y.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of type 1: 59\n",
      "Number of type 2: 71\n",
      "Number of type 3: 48\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "type_1 = (y == 1).sum()\n",
    "type_2 = (y == 2).sum()\n",
    "type_3 = (y == 3).sum()\n",
    "\n",
    "print (f\"Number of type 1: {type_1}\\n\\\n",
    "Number of type 2: {type_2}\\n\\\n",
    "Number of type 3: {type_3}\")\n",
    "\n",
    "# or do print(y.value_counts())\n",
    "\n",
    "# checks out with info found in wine.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.710439</td>\n",
       "      <td>0.683761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.973691</td>\n",
       "      <td>0.87265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Training Accuracy Validation Accuracy\n",
       "SVC                               0.710439            0.683761\n",
       "Decision Tree Classifier          0.973691             0.87265"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, stratify = y)\n",
    "\n",
    "svc = SVC(random_state = 0)\n",
    "dtc = DecisionTreeClassifier(max_depth = 3, random_state = 0)\n",
    "models = [svc, dtc]\n",
    "\n",
    "results = pd.DataFrame(index = [\"SVC\", \"Decision Tree Classifier\"], columns = [\"Training Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "for index in range(len(models)):\n",
    "    model = models[index]\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = cross_validate(model, X_train, y_train, scoring = \"accuracy\", return_train_score = True)\n",
    "    results.iloc[index, 0] = scores['train_score'].mean()\n",
    "    results.iloc[index, 1] = scores['test_score'].mean()\n",
    "    \n",
    "results\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Implement best model\n",
    "\n",
    "# Best model was Decision Tree classifier\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(170.97222222222223, 0.5, 'true value')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAHkCAYAAADvrlz5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlbUlEQVR4nO3df3zP9f7/8fubmR+ZH/MrnCmTKb8y3+zwoQ+hSORHlqL8SKIPOcePSCpFx4wySSlRKScUpsRKSogiEV00zZaYTRTGFtvMXt8/fNrnvPPzPZvXY9vtern44/18vfZ6P6xz3PZ+vd57vzyO4zgCAACuKub2AAAAgCADAGACQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAY4Of2AHnpxzp3uT0CCpiY0xXdHgEF0Nhf17o9AgqYrMykS+7DK2QAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIcmHm8ajSwz10wxdv6MYfo1Vn9WsK7H+321PBuOqhdRS+6EkN3z1XQ757RR2nD1bpSuXcHguGdbijjb75epVOpMQrYc9mjR0zzO2RCiSCXIhVe/JhVRs3UGlfbVfiIxN19K0PVfl/7lO18YPcHg1GVW10vcIXj9fpUxn6cNAMbYhYpOv+u5G6vfFPt0eDUS2a36LoZW9p9+54hd/7sP793lJNmjhW454Y7vZoBY6f2wMgfxSvWE6Bfbvo2KJP9Oszr0qS/pB0+uBvCprzjI4tjFHmzwfcHRLmtH7yfv22a58+HDhdTrYjScpIO6W2zz6ockFVdCLxN5cnhDVPPzVCO3bsUv8BZwP86eovVaKEn8Y8PlRRM+YoPT3d5QkLDl4hF1L+tWvK41dcqZ9v9lr/Y/MP8hQvrrKtb3FpMlhVqkJZBbW4Sd+/uyYnxpIU/8lWzWn+D2KMc/j7+6t16xaKXh7jtb506UoFBJTVra3CXJqsYCLIhdSZo8clSSX+Vs1r3b9W9bPrQdXO+RoUbVVuCpKnWDGd/P2EOr30qB778Q09FjtXd854VCXLl3F7PBgUHFxLJUuWVNyen73W4xN+kSTVrRvswlQFF0EupDJ/SdbJrbtUZXhvBdzRQsXKllGp+sGqMeUfys7IVLHSpdweEcb8+catDi8MUlb6aX04aIbW/es9Bbdroh5vPy55PC5PCGsqlC8vSUo9kea1npp69nG5cgFXfaaCjGvIhVji/0xW9X8NU9DspyRJZ46n6VDkm6oy7D5ln+K6DrwVL3H2n4PDP/yi1WPnSpL2b9yljOMn1fmVYbru1obat/4HN0eEMcWKnf0hzXGc827Pzs6+muMUeK4F+dtvv73kPs2aNbsKkxReZ46k6MCQ51Us4Br5VQvU6f0H5ZzJVvWJQ5Wdkur2eDAmM+2UJCnh8+1e67+s2ylJqtrgOoIMLynHT0iSAsqV9VoPCDj7+Phx/p3xhWtBHj9+vBITEy/4k5XH41FsbOxVnqpwKdf5v5WxZ78yfvpFmal/SJJKNbpBHr/iOrUrweXpYM2xX36VJPn5e/+zUMyvuCQpKz3zqs8E2xIS9ikrK0s31Lnea/3Px7GxcVd/qALMtWvIixYtUlBQkKKiorR79+5z/hDjK1d5aC9VfvRer7VKA7rpzPE0ndy806WpYNXRPck6vv+w6t3dwmu9zu1NJUlJW35yYywYlpGRoQ0bNqt7t05e6/fcc5eOHUvRlm+/d2ewAsq1IAcGBioiIkLTpk3jOkM+OTp/hcrddasqD+2lMs0bq/rzw1S+6206PO1tZf/v6UngP62bvFA1mt6Qc804tP/tum3CA4pbtUWHd+1zezwYNDniJYWFhWrRwtfVscNteu7ZxzVq5KOaEvkyv4PsI49zoXPGV8ny5ct16623qlKlSld8rB/r3JUHExUugf3vVmDfLvKrEqiMnw/oyNxlOrFindtjmRFzuqLbI5gT3K6Jmv+ju6rcGKT0438oNnqTNr7wgc5kZrk9mhljf13r9gimdO3aUROeGaV6IXWUlPSrZr82X1EzXnd7LFOyMpMuuY/rQc5LBBm+IsjIDYIMX11OkPk9ZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGeBzHcdweIq9cW+Emt0dAAZMYv9LtEVAAla5xq9sjoIDJyky65D68QgYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABiQqyAfPnxYs2bN0siRI3XkyBHFxMQoISEhr2cDAKDI8DnI+/btU5cuXRQdHa3Vq1fr5MmTiomJUc+ePbVt27b8mBEAgELP5yBPmTJF7du315o1a1SiRAlJUlRUlNq3b6/p06fn+YAAABQFPgd5+/btGjBggDweT85a8eLFNWTIEMXGxubpcAAAFBU+B/nMmTPKzs4+Zz0tLU3FixfPk6EAAChqfA5yq1atNHv2bJ05cyZn7dixY5o2bZqaN2+ep8MBAFBUeBzHcXz5gkOHDqlv375KSUlRamqqgoODlZSUpAoVKmjBggWqWbNmfs16SddWuMm150bBlBi/0u0RUACVrnGr2yOggMnKTLrkPj4HWZJOnTqljz/+WLGxscrOzlbdunXVtWtXlS1bNleD5hWCDF8RZOQGQYavLifIfrk5cOnSpRUeHp6bLwUAAOfhc5D79u170e3vvPNOrocBAKCo8jnIf71GfPr0ae3fv19xcXHq379/Xs0FAECR4nOQIyIizrs+c+ZMHTly5IoHAgCgKMqzm0t0795dMTExeXU4AACKlDwLcnx8vHLxhm0AAKBcnLIeN27cOWupqanauHGjOnbsmCdDAQBQ1Pgc5AMHDpyz5u/vr4EDB2rAgAF5MhQAAEWNz0F+991382MOAACKtMsKcnJy8mUfsEaNGrkeBgCAouqygty2bVuv2y2ej+M48ng83IIRAIBcuKwg8+lbAADkr8sKclhYWH7PAQBAkebzm7oyMzO1ePFi/fTTT173RM7MzNQPP/yg1atX5+mAAAAUBT4HefLkyVq2bJkaNGigHTt2KDQ0VPv27dORI0f4LGsAAHLJ50/qWrNmjaZMmaKFCxfqb3/7myZNmqS1a9eqXbt2On36dH7MCABAoedzkFNSUtSkSRNJUkhIiH788UeVKFFCgwcP1tq1a/N6PgAAigSfg1y5cuWcuzrVqlVLcXFxkqSKFSvq999/z9vpkGdq1LxWP+3brP9q1cztUWDUwUO/qUWHntqybWfOWsOWd17wz4BhY12cFpZ0uKONvvl6lU6kxCthz2aNHTPM7ZEKJJ+vIbdu3VoTJkxQRESEmjZtqn/961+6/fbbtWrVKl177bX5MSOu0N+Camjh0jdUvnw5t0eBUcm/HtLgEU8pNe0Pr/V/vz79nH3XrNukt95bovBud16t8WBYi+a3KHrZW3r/gxWaMGGqWrYM06SJY1WsWDFFTJnp9ngFis9BHj16tMaOHautW7eqd+/eev/99xUeHi4/Pz9FRkbmx4zIJY/Ho169u+mZSWPcHgVGZWdn68OYNXph1tzzbr+54U1ejw/+elhLPorR/T26qFP7NldhQlj39FMjtGPHLvUfMFyS9OnqL1WihJ/GPD5UUTPmKD093eUJCw6fT1kHBATo1VdfVZ8+feTxeDRnzhwtW7ZMX3zxhe666678mBG5VL9hPU15cYLeX7hcjw3m9CLOFRe/V5NemKWud7ZXxNOjL7n/1JfnqFTJkvrHkH5XYTpY5+/vr9atWyh6eYzX+tKlKxUQUFa3tuIzLHzhc5Dbtm2rmTNnKjExMWetfv36qlq1ap4OhiuXlHhQLZp20LPjI3Xq1Cm3x4FB1a+tqlWL52nM8EdUqlSpi+67/Ycf9dmXG/WPwf1V9pprrtKEsCw4uJZKliypuD0/e63HJ/wiSapbN9iFqQoun4McHh6uTz/9VHfccYd69+6tJUuWKC0tLT9mwxVKSTmug8mH3B4DhpUvF6Brq1a5rH3fem+Jalavps4d2ubzVCgoKpQvL0lKPeHdgNTUs4/LlQu46jMVZD4H+dFHH9XKlSv1wQcfqEGDBpoxY4ZatWqlxx9/XJs2bbqsYxw7dkxDhgxRs2bN1L9/f8XHx3ttb9q0qa9jAchHBw/9pi+/2qwH7u0mP7/ibo8DI4oVO3vTIcdxzrs9Ozv7ao5T4Pkc5D81bNhQ48eP1/r16zV69Gh98cUXGjhw4GV97ZQpU+Q4jiIjI1W1alX16dPHK8oX+o8LwB1r1m2UxyPd2b6126PAkJTjJyRJAeXKeq0HBJx9fPx46lWfqSDz+V3Wf0pOTtbHH3+sFStWKCEhQWFhYerRo8dlfe3GjRu1cuVKlS9fXm3btlVUVJQGDx6sZcuWqXz58pe81SOAq2vdxi36fzc3UuXAim6PAkMSEvYpKytLN9S53mv9z8exsXFXf6gCzOdXyIsWLVKfPn3Uvn17ffDBB+rYsaPWrFmjt99+W3ffffdlHeP06dMqW/b/fqIaMWKE6tevr5EjR0riFTJgieM42rU7TqGN6rs9CozJyMjQhg2b1b1bJ6/1e+65S8eOpWjLt9+7M1gB5XOQIyMjVatWLc2fP1+fffaZhg4dqho1avh0jAYNGmj27Nle4Y2IiFBSUpKefPJJX0cCkI8OHjqs1LQ/VKd2LbdHgUGTI15SWFioFi18XR073Kbnnn1co0Y+qimRL/M7yD7y+ZT1xo0bVaZMmSt60jFjxmjQoEHauXOn5syZI0kqW7as5syZo379+vEfETDkyNEUSVK5gLIX3xFF0tovNyq81yBNeGaUli6Zp6SkXzX2iecVNeN1t0crcDyOS+eHMzIylJycrNq1a3utnzhxQsuWLcvVrRyvrXDTpXcC/kNi/Eq3R0ABVLrGrW6PgAImKzPpkvu4FuT8QJDhK4KM3CDI8NXlBDnXv/YEAADyDkEGAMCAXAX58OHDmjVrlkaOHKkjR44oJiZGCQkJeT0bAABFhs9B3rdvn7p06aLo6GitXr1aJ0+eVExMjHr27Klt27blx4wAABR6Pgd5ypQpat++vdasWaMSJUpIkqKiotS+fXtNn37uzcwBAMCl+Rzk7du3a8CAAV4fb1m8eHENGTJEsbGxeTocAABFhc9BPnPmzHnv4JGWlqbixbkLDAAAueFzkFu1aqXZs2frzJkzOWvHjh3TtGnT1Lx58zwdDgCAosLnDwY5dOiQ+vbtq5SUFKWmpio4OFhJSUmqUKGCFixYoJo1a+bXrJfEB4PAV3wwCHKDDwaBr/Ltk7pOnTqljz/+WLGxscrOzlbdunXVtWtXrzs4uYEgw1cEGblBkOGrywlyru6HXLp0aYWHh+fmSwEAwHn4HOS+fftedPs777yT62EAACiqfA7yX68Rnz59Wvv371dcXFyu7tAEAAByEeSIiIjzrs+cOVNHjhy54oEAACiK8uzmEt27d1dMTExeHQ4AgCIlz4IcHx+vQnRrZQAAriqfT1mPGzfunLXU1FRt3LhRHTt2zJOhAAAoanwO8oEDB85Z8/f318CBAzVgwIA8GQoAgKLG5yA/9thjatKkifz9/fNjHgAAiiSfryEPHz5ce/bsyY9ZAAAosnwOcqVKlZSampofswAAUGT5fMq6VatWGjx4sFq3bq3rrrtOJUuW9No+bNiwPBsOAICiwuebS7Rt2/bCB/N49Pnnn1/xULnFzSXgK24ugdzg5hLwVb7cXOKLL7644Lbs7GxfDwcAAJSLa8jt2rVTSkrKOeuHDh1SixYt8mImAACKnMt6hbxq1Spt2LBBkpSUlKSJEyeec+04KSlJHo8n7ycEAKAIuKwgh4aGatGiRTkfjZmcnKwSJUrkbPd4PCpTpowiIyPzZ0oAAAq5ywpy9erVc+5z/OCDD+qVV15RuXLl8nUwAACKEp/f1PXuu+/mxxwAABRpeXa3JwAAkHsEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAb4uT1AXvr95Am3R0ABE3TDXW6PgALo9+4hbo+AQohXyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIciHX4Y42+ubrVTqREq+EPZs1dswwt0dCAVGj5rX6ad9m/VerZm6PAqM8laqo/Jsr5Ff/Zp+24fwIciHWovktil72lnbvjlf4vQ/r3+8t1aSJYzXuieFujwbj/hZUQ4uj56l8+XJujwKjPJWrqez4F+S5pqxP23Bhfm4PgPzz9FMjtGPHLvUfcDbAn67+UiVK+GnM40MVNWOO0tPTXZ4Q1ng8HvXq3U3PTBrj9iiwyuORf+sOKvXAEN+24ZJ4hVxI+fv7q3XrFopeHuO1vnTpSgUElNWtrcJcmgyW1W9YT1NenKD3Fy7XY4PHuj0ODCpeK1ilB45Q5rrVOjkr4rK34dJ4hVxIBQfXUsmSJRW352ev9fiEXyRJdesG67M1612YDJYlJR5Ui6YddDD5ENeOcV7Zvx/WiX/0kXP093OuD19sGy7NTJBTU1NVunRp+fmZGalAq1C+vCQp9USa13pq6tnH5coFXPWZYF9KynGlpBx3ewwY5vyRKv2R6vM2XJorp6wzMjI0a9Ysvffee0pPT9egQYMUFhampk2batKkSTp9+rQbYxUqxYp5JEmO45x3e3Z29tUcBwBwCa68HJ02bZo2b96szMxMxcTEyOPxaPHixcrMzNTUqVM1e/ZsDR/OO4GvRMrxE5KkgHLe73IMCDj7+PhxfooFAEtcCfInn3yi5cuX6+jRo+ratavWr1+vKlWqSJKioqLUt29fgnyFEhL2KSsrSzfUud5r/c/HsbFxV38oAMAFuXLK+tSpU6pcubJCQkJUtWpVlf/f652SVLVqVaWm8urtSmVkZGjDhs3q3q2T1/o999ylY8dStOXb790ZDABwXq4EuU6dOlq+fLkkad26dfL395ckZWVlafr06WrUqJEbYxU6kyNeUlhYqBYtfF0dO9ym5559XKNGPqopkS/zO8gAYIwrp6xHjBihIUOG6I477lCZMmVy1rt06aKMjAy98cYbboxV6Kz9cqPCew3ShGdGaemSeUpK+lVjn3heUTNed3s0AMBfeJwLvQ03nx09elSBgYFea9u3b1e9evW8Iu0LP/+aeTEaipDKZfhoSPhud4dr3R4BBUyFxWsvuY9rv/T71xhLUmhoqAuTAADgPj46EwAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABHsdxHLeHAACgqOMVMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEOQi4ujRo7r99tu1efNmt0eBcbt379aAAQMUFhamli1basyYMTp69KjbY8Gwr7/+WuHh4WratKlatmypSZMmKT093e2xChyCXAR899136tWrl/bv3+/2KDAuPT1dDz/8sEJDQ/XVV1/p448/VkpKip588km3R4NRR48e1eDBg3X//fdr69atio6O1pYtWzRnzhy3RytwCHIhFx0drdGjR2vEiBFuj4ICIDk5WTfeeKOGDh0qf39/VaxYUb169dK3337r9mgwKjAwUJs2bVKPHj3k8XiUkpKijIwMBQYGuj1agUOQC7lWrVrps88+U6dOndweBQVAcHCw5s6dq+LFi+esffrpp2rQoIGLU8G6smXLSpJat26tLl26qEqVKurRo4fLUxU8BLmQq1Klivz8/NweAwWQ4ziKiorS2rVrNX78eLfHQQGwevVqrV+/XsWKFdPw4cPdHqfAIcgAzpGWlqbhw4drxYoVWrBggerVq+f2SCgASpUqpWrVqunxxx/Xhg0bdPz4cbdHKlAIMgAv+/fv1z333KO0tDQtWbKEGOOitm3bpo4dOyozMzNnLTMzUyVKlFDp0qVdnKzgIcgAchw/flz9+vVT06ZNNW/ePN6Yg0uqV6+e0tPT9eKLLyozM1NJSUmKjIxUz5495e/v7/Z4BQoXFwHkWLZsmZKTkxUTE6NPPvnEa9v27dtdmgqWXXPNNZo7d64mT56sli1bKiAgQF26dNHQoUPdHq3A8TiO47g9BAAARR2nrAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQgQKqbdu2evnllyWd/YQtXz5zeu3atYqPj7+i53/wwQf1xBNPXNExLuY//35AUUCQgUKgU6dO+uqrry5r36SkJA0ZMkRHjhzJ56kA+ILPsgYKgVKlSqlUqVKXtS+flgvYxCtkIA/Vq1dPCxcu1P3336/GjRurS5cu+vzzz3O2v/zyy7rvvvs0cuRINW3aVM8995yks7ew69Onjxo3bqw2bdroueeeU1paWs7XpaamauzYsbrlllvUokULvf32217P+9dT1idPntTzzz+vVq1aKTQ0VH369NHOnTt14MABtWvXTpLUt2/fnFPCCQkJGjRokEJDQ9WqVSuNGjVKv/32W87xMjMzNXnyZLVo0UK33HKLXnzxRWVnZ1/w+/DEE08oPDzca+3XX3/VTTfdpK+//lqStHTpUnXr1k2NGzdWkyZN9OCDD2rXrl3nPd75Tslv3rxZ9erV04EDBySd/UHjjTfeULt27XTzzTera9eu+uijjy44I2ANQQby2NSpU9W5c2ctX75crVu31rBhw7Rt27ac7du3b1elSpX04Ycfql+/ftq9e7f69++vli1b6qOPPtILL7ygXbt26aGHHsp5NfvPf/5TO3fu1GuvvaY333xTa9euVVJS0gVnGDFihNauXavJkydr+fLlql27tgYOHKhSpUrpgw8+kHT2h4OHHnpIhw4dUu/evRUUFKQlS5botddeU1pamu677z6dPHlSkvT8889r1apVmjJlihYuXKjk5GRt3br1gs/fvXt37dy5U/v27ctZ++ijj1StWjX9/e9/12effaYJEyaof//+iomJ0fz585Wenq7x48fn+vseFRWl9957T0899ZRWrFihvn376tlnn9W///3vXB8TuKocAHkmJCTEmTRpktfavffe64wYMcJxHMeZOXOmExIS4pw4cSJn++jRo51HHnnE62v279/vhISEON98842TkJDghISEOJs2bcrZ/ttvvzkNGzZ0Zs6c6TiO4yxdutQJCQlxHMdxfv75ZyckJMRZv359zv4ZGRnO5MmTnYSEBCcxMTHn2I7jOFFRUU7nzp29nv/kyZNO48aNnaVLlzqpqalOgwYNnPfffz9ne3p6utOyZUtn7Nix5/0+ZGdnO+3atXNefvnlnLXOnTs706dPdxzHcbZs2eJER0d7fc3ixYudG2+8Mefxbbfddt6/35+++eYbJyQkxElMTHT++OMPp1GjRk5MTIzXPi+99JJz2223nXdGwBquIQN5LCwszOvxzTffrE2bNuU8rlSpkgICAnIe//jjj9q3b59CQ0PPOVZCQoKOHTsmSWrUqFHOeuXKlRUUFHTe5//pp58kSU2aNMlZ8/f317hx4yQp5xTvfz5/QkLCOc+fkZGhhIQE7d27V6dPn/Z6/pIlS+qmm2467/NLksfjUbdu3bRixQoNGzZMsbGxiouL08yZMyVJzZo1U2BgoF599VXt27dPe/fuVWxs7EVPg19MfHy8MjIyNHbs2Jy/pyRlZWUpMzNT6enpl32NHXALQQbymJ+f9/+tsrOzVazY/10d+msYsrOz1aVLFw0ZMuScYwUGBmrjxo05+13sef667vF4Lmve7OxsNW/eXBMmTDhnW0BAwAVPjV/o+f/UvXt3zZo1Szt37lRMTIxCQ0NVu3ZtSdLKlSs1ZswYde7cWY0bN1bPnj0VFxeniRMnXvSYjuPk/L2ysrK81iVpxowZCg4OPufr/P39L3pcwAKuIQN57IcffvB6/P3336tBgwYX3L9u3bras2ePrrvuupw/Z86cUUREhA4ePKj69etLktd16BMnTmj//v3nPV6dOnXOmSMrK0tt2rTRypUrzwl13bp1lZCQoOrVq+c8f/ny5TV58mTFxcWpTp06KlmypL777juv4+3evfui34eaNWsqLCxMn3zyiVatWqXu3bvnbHvttdfUs2dPRUZGqk+fPmrWrJkSExMlnf9d4CVKlJB09s1tf/rP69PBwcHy8/NTcnKy1/dx3bp1mjdvntcPRIBV/K8UyGPz58/XihUrtHfvXkVGRmr37t3q16/fBfd/6KGHFBsbq2eeeUbx8fHasWOHRo8erb179+r6669XrVq11LFjR02cOFGbNm1SXFycxowZo8zMzPMer3bt2rrjjjv03HPP6euvv9bevXv1zDPPKDMzUy1atFCZMmUkSXFxcUpNTVXv3r2VmpqqkSNHKjY2Vrt379aoUaO0c+dO1a1bV2XKlNEDDzygmTNnavXq1UpISNCECRN06NChS34vevTooUWLFunYsWPq1KlTznr16tW1bds27dq1S/v379fbb7+tBQsWSNJ5/15NmjRRsWLFNGPGDCUmJurLL7/Um2++mbM9ICBA9913n2bMmKHly5crMTFR0dHRmjZtmipXrnzJOQELCDKQx3r16qW33npLd999t7Zu3ap58+bpxhtvvOD+TZo00dy5cxUXF6cePXrokUceUVBQkN56662cU62RkZFq06aNRowYoT59+uiGG25Qw4YNL3jMiIgIhYWFacSIEerRo4eSk5P15ptvKjAwUBUrVtQ999yjqVOn6qWXXlJQUJAWLFigU6dOqXfv3nrggQfk8Xg0f/58VapUSZI0atQo9e7dWxMnTlTPnj3lOI7atm17ye9Fhw4dJEnt27f3um7+9NNPq3LlynrggQcUHh6utWvXaurUqZKkHTt2nHOcoKAgTZw4UevWrdOdd96p2bNn68knn/TaZ9y4cerfv79mzpypO++8U6+88oqGDRumxx577JJzAhZ4nPOdHwKQK/Xq1VNERIR69Ojh9igAChheIQMAYABBBgDAAE5ZAwBgAK+QAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAY8P8BLz/WsNPWKI8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(matrix, square = True, annot = True, cbar = False, xticklabels = [1, 2, 3], yticklabels = [1, 2, 3,])\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.60      0.72        15\n",
      "           2       0.71      0.94      0.81        18\n",
      "           3       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.82        45\n",
      "   macro avg       0.87      0.82      0.83        45\n",
      "weighted avg       0.85      0.82      0.82        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "1. Both the training and validation accuracy are higher for the decision tree classifier. The SVC's training score was ~0.7, while the decision tree classifier's training score was ~0.97. The SVC's validation score was ~0.68, while the decision tree classifier's validation score was ~0.87. It is also worth noting that the SVC scores were similar to each other, indicating high bias, while the decision tree's scores were further apart, indicating high variance.\n",
    "\n",
    "2. Since the SVC model didn't perform as well because the model is not as complex as the devision tree. This is demonstrated in its higher bias.\n",
    "\n",
    "3. 8 samples were predicted incorrectly.\n",
    "\n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. I sourced my code from Decision Tree Example from D2L. Specifically, I used it to see how to create the confusion matrix.\n",
    "2. I completed the steps in chronological order.\n",
    "3. I did not use generative AI. The course slides/examples and scikit website provided enough material.\n",
    "4. I didn't face many challenges during this part of the assignment. The code throughout this part was either similar to part 1 or the previous assignment, or similar to the examples found on D2L. Perhaps the biggest challenge I faced was creating the X and y datasets in the beginning. Since there were no column headers in the \"wine.data\" file, I just had to read the documentation from the website or the \"wine.names\" file to find the column names so I could figure out which column was the target vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "I liked that this assignment gave me more practice in interpreting results, specifically, comparing training and validation scores of a particular model. I gained more confidence in being able to determine if a model is high variance or high bias. I also enjoyed the data import step in part 2. The process was a little bit different than loading a Yellowbrick dataset, and it was interesting exploring the dataset's webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
